{"cells":[{"cell_type":"code","execution_count":247,"metadata":{},"outputs":[],"source":"import os\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.utils.data\n\nfrom torch import nn, optim\nfrom torch.autograd import Variable\nfrom torch.nn import functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Uncertainty\n\n## Types of uncertainty\n\n### Epistemic uncertainty\n\n### Aleatory uncertainty\n\n\n\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Some existing methods for modelling uncertainty\n\n## Monte Carlo Dropout\n\n## Distributional Parameter Learning\n\n## Ensemble Averaging\n\n## Dropout Ensembles\n\n## Quantile Regression\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# Uncertainty modelling example\n\n## Function\n\n$$ y_i = f(x_i) + \\epsilon_i, \\hspace{1cm} \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$$\n"},{"cell_type":"code","execution_count":407,"metadata":{},"outputs":[],"source":"N_SAMPLES = 32\nSIGMA = 1  # Data standard deviation\nBATCH_SIZE = 16\nN_EPOCHS = 5000"},{"cell_type":"code","execution_count":408,"metadata":{},"outputs":[],"source":"np.random.seed(42)"},{"cell_type":"code","execution_count":409,"metadata":{},"outputs":[],"source":"# Data generating function\ndef f(x, sigma):\n    y = 2 * np.sin(x + 0.5) + 3 * np.cos(0.7 * x) #  + (0.1 * x) ** 3\n    eps = np.random.normal(loc=0, scale=sigma)\n    return y + eps"},{"cell_type":"code","execution_count":410,"metadata":{},"outputs":[],"source":"# Training data\nx_1 = np.random.uniform(-10, -5, size=N // 2)\nx_2 = np.random.uniform(0, 5, size=N // 2)\nx_train = np.concatenate([x_1, x_2]).reshape(N, 1)\ny_train = f(x_train, sigma=SIGMA).reshape(N, 1)\ndataset_train = torch.utils.data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\ndataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE)"},{"cell_type":"code","execution_count":411,"metadata":{},"outputs":[{"data":{"text/plain":"<matplotlib.collections.PathCollection at 0x131031b00>"},"execution_count":411,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":"<Figure size 432x288 with 1 Axes>\n"}],"source":"x_plot = np.linspace(-15, 15, num=200)\nfig, ax = plt.subplots(1, 1)\nax.plot(x_plot, f(x_plot, sigma=0), label='Data generating function')\nax.scatter(x_train, y_train, label='Training data')"},{"cell_type":"code","execution_count":412,"metadata":{},"outputs":[],"source":"def gaussian_nll(mu_true, mu_pred, sigma_pred):\n    return np.log(sigma_pred ** 2) / 2 + ((mu_true - mu_pred) ** 2) / (2 * sigma_pred ** 2)"},{"cell_type":"code","execution_count":413,"metadata":{},"outputs":[],"source":"class GaussianNLLLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, mu_true, mu_pred, logvar_pred):\n        var_pred = logvar_pred.exp()\n        return torch.mean(var_pred.log() / 2 + (mu_true - mu_pred).pow(2) / (2 * var_pred), axis=0)"},{"cell_type":"code","execution_count":414,"metadata":{},"outputs":[],"source":"class DPLModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lin1 = nn.Linear(1, 10)\n        self.act1 = nn.ELU()\n        self.lin2 = nn.Linear(10, 2)\n\n    def forward(self, x):\n        x = self.lin1(x)\n        x = self.act1(x)\n        x = self.lin2(x)\n        mu = x[..., 0:1]\n        logvar = x[..., 1:2]\n        return mu, logvar"},{"cell_type":"code","execution_count":415,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 4999 | Loss 1.549"}],"source":"model = DPLModel()\nmodel.to(device)\n\ngaussian_nll_loss = GaussianNLLLoss()\nloss.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=3e-4)\n\nfor epoch in range(N_EPOCHS):\n    for x_batch, y_batch in dataloader_train:\n        x_batch.to(device)\n        y_batch.to(device)\n\n        optimizer.zero_grad()\n\n        y_pred, _ = model.forward(x_batch)\n\n        loss = gaussian_nll_loss(y_batch, y_pred[0], y_pred[1])\n\n        loss.backward()\n\n        optimizer.step()\n        print(f'Epoch {epoch:3d} | Loss {loss[0].item():2.3f}', end='\\r')"},{"cell_type":"code","execution_count":416,"metadata":{},"outputs":[{"data":{"text/plain":"<bound method Axes.plot of <matplotlib.axes._subplots.AxesSubplot object at 0x1318ef5c0>>"},"execution_count":416,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":"<Figure size 432x288 with 1 Axes>\n"}],"source":"x_plot_tensor = torch.Tensor(x_plot.reshape(-1, 1))\nx_plot_tensor.to(device)\n\nlearned_function = model.forward(x_plot_tensor)\nfig, ax = plt.subplots(1, 1)\nax.plot(x_plot, f(x_plot, sigma=0), label='Data generating function')\nax.plot"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}